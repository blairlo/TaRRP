---
title: "InstallationClassifier"
author: "Logan"
date: '2022-07-20'
output: html_document
---
# Prelims
```{r}
library(tmap) 
library(mapview)
library(sf)
library(raster)
library(stringr)
library(questionr)
library(dplyr)
library(tidyr)
library(rgdal)
library(rgeos)
library(ggplot2)
library(MASS)
library(pscl)
library(visreg)
library(mlogit)
library(rstanarm)
library(loo)
library(bayesplot)
library(shinystan)
library(readxl)
library(reshape2)
library(data.table)
library(randomForest)
require(caTools)
library(tidycensus)
library(stargazer)
library(exactextractr)
library(gplots)
library(gtools)
library(DescTools)
library(reticulate)
library(sen2r)
library(leafem)
library(parallel)
library(pbapply)

options(rasterMaxMemory = 3e10)
options(rasterTmpTime = 1)
```


### Custom Helper Function to Mosaic/Merging
The following function helps mosaic, merge, and reclassify values of a list of rasters. 

```{r}
MosaicReclassRaster <- function(Location, # Location of raster (.tif) files
                                Mosaic = "Y", #mosic(Y) or merge(N)
                                bands = FALSE, #Select a specific band, if false all bands will be returned
                                Reclass0toNA=FALSE){ #If TRUE, converts 0 values to NA
  
current.list <- list.files(path=paste(Location), full.names=TRUE, pattern = ".tif")
  
   #read in raster files as a raster stack
  raster.list <- lapply(current.list, raster::stack)
  
if (bands > 0) {
  #select band if interested in only 1
  raster.list <- lapply(current.list, raster, band=bands)
  
} else{}
  
if (Reclass0toNA==TRUE) {
  #reclassify 0 (unusable pixels) as NA
  reclass_na <- matrix(c(0, NA),
                ncol = 2,
                byrow = TRUE) #reclass matrix
      raster.list <- lapply(raster.list, raster::reclassify, reclass_na)
      
} else {}
  
 if (Mosaic == "Y"){
  #if Y, average any overlapping pixels and mosaic, ignore NA
  raster.list$fun <- mean
    Mosaic <- do.call( raster::mosaic, raster.list)
    
 } else {
    #if N, take value in first raster in the list (instead of average) unless it is NA
    Merge <- do.call( raster::merge, raster.list)
 }
}
```

### Mosaic training images by date
I Use 2 County wide composites for training--one from January and one in June to capture variability in grass/foliage as well as faded blue coler from wearthering.
```{r}
#Run function on folders containing images by date
#Groups together represent full coverage of bay county


Mimages_01_19<-MosaicReclassRaster("PlanetData/Monthly/01_2019",
                                  Mosaic= "N", 
                                  bands = FALSE, 
                                  Reclass0toNA = TRUE)
writeRaster(Mimages_01_19,"PlanetData/Monthly/Composite_Mimages_01_19.tif")

Mimages_08_19<-MosaicReclassRaster("PlanetData/Monthly/08_2019",
                                  Mosaic= "N", 
                                  bands = FALSE, 
                                  Reclass0toNA = TRUE)
writeRaster(Mimages_08_19,"PlanetData/Monthly/Composite_Mimages_08_19.tif")


```


# Classification

### Load training footprints
These are training data derived from high res January imagery in the case of "no tarp" training plots, and predicted/cleaned program footprint from the Program classifier.

```{r}
#read in training plots (program)
Tarp<-st_zm(read_sf("Building Data/Programids_SA.shp"))
TarpUpdate1<-st_zm(read_sf("Building Data/NonProgramids_SA.shp"))
TarpUpdate2<-st_zm(read_sf("Building Data/Programid_SA_June.shp")) #same as January but relevant in June
TarpUpdate3<-st_zm(read_sf("Building Data/NonProg_SA_June.shp")) #same as January but relevant in June

#read in training plots (roof/other)
NoTarp<-st_zm(read_sf("Building Data/RoofMaster.shp")) #relevant for Jan and June
NoTarpUpdate<-st_zm(read_sf("Building Data/RoofUpdateX.shp"))#relevant for Jan and June

```

### Function extract image by footprint and save seperatly as .tif(s)
```{r message=FALSE, warning=FALSE, include=FALSE}

#function with 4 arguments
ClipRasterSave <- function(raster,clippingfeatures,outpath,labelvar){

#make projections equal
clippingfeaturesproj<-st_transform(clippingfeatures, crs(raster))

#crop training plots that overlap image
CroppedFeatures<-st_crop(clippingfeaturesproj, extent(raster))

#make 3 band
raster<- dropLayer(raster,4)

#check to make sure features and images overlap. 
if (length(CroppedFeatures$geometry) > 0) { #If so run:
  
         clip.list<-lapply(1:nrow(CroppedFeatures), function(x)
          #crop imagery to the footprint extents and mask over non-footprint pixel
            clips<-raster::mask(crop(raster, 
                                     extent(CroppedFeatures[x,])), 
                                     CroppedFeatures[x,]))
        
names(clip.list) <- paste0(CroppedFeatures[[labelvar]],"2")#Add additional strings here if you need to make custom names

mapply(writeRaster
       ,clip.list
       ,file=paste0(outpath, names(clip.list)) #export by name
       ,overwrite=TRUE
       ,format="GTiff"
       ,datatype="INT1U"
       #,options="TFW=YES"
      )

} else { 
#if not return nothing (to avoid a problematic error in loops)
}
  }

```


### Extract image by footprint
```{r}
#Clip training footprints by Tarp and No tarp. Save in appropriate training folder by type.

#Tarp Properties and updates
TarpClips<-ClipRasterSave(Mimages_01_19
                 ,clippingfeatures = Tarp
                 ,outpath = "MInstallationClips/train/Tarp/"
                 ,labelvar = "GlblIDF"
                  )

TarpClips<-ClipRasterSave(Mimages_01_19
                 ,clippingfeatures = TarpUpdate1
                 ,outpath = "MInstallationClips/train/Tarp/"
                 ,labelvar = "GlblIDF"
                  )

TarpClips<-ClipRasterSave(Mimages_08_19
                 ,clippingfeatures = TarpUpdate2
                 ,outpath = "MInstallationClips/train/Tarp/"
                 ,labelvar = "GlblIDF"
                  )

TarpClips<-ClipRasterSave(Mimages_08_19
                 ,clippingfeatures = TarpUpdate3
                 ,outpath = "MInstallationClips/train/Tarp/"
                 ,labelvar = "GlblIDF"
                  )

#Bare roof/no tarp footprints
NoTarpClips<-ClipRasterSave(Mimages_01_19
                 ,clippingfeatures = NoTarp
                 ,outpath = "MInstallationClips/train/@NoTarp/"
                 ,labelvar = "GlobalID"
                  )


NoTarpClips<-ClipRasterSave(Mimages_01_19
                 ,clippingfeatures = NoTarpUpdate
                 ,outpath = "MInstallationClips/train/@NoTarp/"
                 ,labelvar = "GlobalID"
                  )

NoTarpClips<-ClipRasterSave(Mimages_08_19
                 ,clippingfeatures = NoTarpUpdate
                 ,outpath = "MInstallationClips/train/@NoTarp/"
                 ,labelvar = "GlobalID"
                  )

NoTarpClips<-ClipRasterSave(Mimages_08_19
                 ,clippingfeatures = NoTarpUpdate
                 ,outpath = "MInstallationClips/train/@NoTarp/"
                 ,labelvar = "GlobalID"
                  )


```
# ML Model
### Install Karas / Tensor Flow

We'll need to pull in some additional machine learning software and packages with pre-trained NNs
```{r}
#install.packages("keras")
#install_tensorflow()
#reticulate::install_miniconda()
library(keras)
library(tensorflow)
library(reticulate) #python-R Bridge

#if issues try a different (older version
#install_keras(tensorflow = "2.5.0", extra_packages="pillow") #be sure this matched your tensorflow version installed
#install_tensorflow(version = "2.5.0", extra_packages="pillow")



```

### Describe image data
```{r}
label_list <- dir("MInstallationClips/train/")
output_n <- length(label_list)
save(label_list, file= "label_list.R")
width <- 5
height<- 5
target_size <- c(width, height)
rgb <- 3 #color channels

#assign rescale values and training split
train_data_gen <- image_data_generator(
  rescale = 1/255, 
  validation_split = .3,
  #width_shift_range = 0.1,
  #height_shift_range = 0.1,
  brightness_range = c(0.95, 1.05),
  rotation_range=30,
  #shear_range = .1,
  horizontal_flip = TRUE,
  vertical_flip = TRUE
  )

#subset training set
train_images <- flow_images_from_directory("MInstallationClips/train/"
  ,train_data_gen
  ,subset = 'training'
  ,target_size = target_size
  ,class_mode = "categorical"
  ,shuffle=F
  ,classes = label_list
  ,seed = 42
  )

#subset validation set
validation_images <- flow_images_from_directory("MInstallationClips/train/"
 ,train_data_gen
 ,subset = 'validation'
 ,target_size = target_size
 ,class_mode = "categorical"
 ,shuffle=F
 ,classes = label_list
 ,seed = 42
 )


#verify
#table(train_images$classes)

#plot(as.raster(train_images[[1]][[1]][3,,,]))
```

#model
```{r}

# Write model perameters
model_function <- function(
  learning_rate = 0.0005, 
  dropoutrate=0.2, 
  n_dense=75){
  
  #k_clear_session()
  
  model <- keras_model_sequential() %>%
    layer_flatten(input_shape = c(width, height, 3)) %>%
    layer_dense(units = n_dense, activation = 'relu') %>%
    layer_dropout(dropoutrate) %>%
    layer_dense(units = n_dense, activation = 'relu') %>%
    layer_dropout(dropoutrate) %>%
    layer_dense(units=output_n, activation="softmax")
  
  model %>% compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_adam(lr = learning_rate),
    metrics = "accuracy"
  )
  
  return(model)
  
}

model <- model_function()
model
```


### fit model to highest layer (training data)
```{r}
#if model not in-memory
batch_size <- 32
epochs <- 1000

hist <- model %>% fit_generator(
  train_images, # our training data from above
  steps_per_epoch = train_images$n %/% 
  batch_size, 
  epochs = epochs, 
  validation_data = validation_images, # our validation data from above
  validation_steps = validation_images$n %/% 
  batch_size,
  verbose = 2,
  
  #callback and checkpoint saves
  callbacks = list(
    
  #stop for condition
   # callback_early_stopping(monitor = "val_loss", 
   # mode = "min", 
   # patience = 50),
    
  #avoid overwriting the model file unless val_accuracy has improved.
    callback_model_checkpoint(
    filepath = "Checkpoint_Model_Month5.h5",
    monitor = "val_loss",
    mode = "min",
    save_best_only = TRUE)
  )
   )

model %>% save_model_hdf5("Model_Month5.h5")

plot(hist)

```




### evaluate holdout test set
```{r}
path_test <- "MInstallationClips/test/" #set path to the test data

test_data_gen <- image_data_generator(rescale = 1/255) #rescale as before

#load "best" model
model <- load_model_hdf5("Checkpoint_Model_Month4.h5")

test_images <- flow_images_from_directory(path_test,
   test_data_gen,
   target_size = target_size,
   class_mode = "categorical",
   classes = label_list,
   shuffle = F,
   seed = 42)

model %>% evaluate(test_images)
model %>% evaluate(validation_images)

```

# Predict full data

###load most recent model weights if not in-memory
```{r}
#"best" model
model <- load_model_hdf5("Checkpoint_Model_Month4.h5")

```

### Funtion to loop over footprints/ imagery and predict
```{r}
PredictRasterClips <- function(raster,clippingfeatures,labelvar, model=model){

#make projections equal
clippingfeaturesproj<-st_transform(clippingfeatures, crs(raster))

#crop training plots that overlap image
CroppedFeatures<-st_crop(clippingfeaturesproj, extent(raster))

#make 3 band
raster<- dropLayer(raster,4)

#check to make sure features and images overlap. 
  if (length(CroppedFeatures$geometry) > 0) { #If so run:

#perform extraction and prediction at the row level
    clip.list<-lapply(1:nrow(CroppedFeatures), function(x){

          #crop imagery to the footprint extents and mask over non-footprint pixel
            clips<-raster::mask(crop(raster, 
                                     extent(CroppedFeatures[x,])), 
                                     CroppedFeatures[x,])
            
            #save clip as a temporary .tif
            writeRaster(clips
                  ,filename ="x.tif"
                  ,overwrite=TRUE
                  ,format="GTiff"
                  ,datatype="INT1U"
                  #,options="TFW=YES"
                  )
            
#load image
width <- 5
height<- 5
target_size <- c(width, height)
test_image <- image_load("x.tif", target_size = target_size)
y <- image_to_array(test_image)
y <- array_reshape(y, c(1, dim(y)))
y <- y/255

#Predict image
pred <- model %>% predict(y)%>%
         cbind(CroppedFeatures[x,][labelvar])
  
  })

#compile list of individual predictions as a data frame by image
pred<-as.data.frame(do.call(rbind,clip.list))%>%
                                rename(NoTarpProb = X1,
                                       TarpProb  = X2) %>%
  
                  #make prediction based on membership prob.
                  mutate(TarpPred = ifelse(TarpProb > NoTarpProb, 1,0))
                  
                          
 
} else { 
#if not return nothing (to avoid a problematic error in loops)
}

  }

```

### Predict image by footprint across multiple rasters
```{r}

#read in Bay county footprints and match crs
Footprints<-st_zm(read_sf("Building Data/BuildingFootprints.shp")) %>%
                            select(GlobalIDFootprint = GlobalID)%>%
                                st_make_valid()

footprinttest<-head(Footprints)

#read in raster(s) if not in memory
Mimages_01_19<-stack("PlanetData/Monthly/Composite_Mimages_01_19.tif")

#run loop
Program_Predicted_10_19<-PredictRasterClips(Mimages_01_19
                      ,clippingfeatures = footprinttest 
                      ,labelvar = "GlobalIDFootprint"
                      ,model=model
                      )


#convert list of data frames to single data frame
Program_Predicted_10_19 <- as.data.frame(do.call(rbind,Program_Predicted_10_19))

Program_Predicted_10_19 <-left_join(Footprints,Program_Predicted_10_19, by="GlobalIDFootprint")%>%
                                    filter(!is.na(ProgramProb))

st_write(Program_Predicted_10_19,"Building Data/Program_Predicted_10_19.shp",append=TRUE)

```

### Create Installation index based on prediction week
```{r}
Install_Predicted <- cbind (st_read("Building Data/Program_Predicted_10_19.shp")%>%
                                        mutate(TarpP1 = PrgrmPrd)%>%
                                        select(GlblIDF,TarpP1),
                            st_read("Building Data/Program_Predicted_10_31.shp")%>%
                                        mutate(TarpP2 = PrgrmPrd)%>%
                                        select(TarpP2),
                            st_read("Building Data/Program_Predicted_11_16.shp")%>%
                                        mutate(TarpP3 = PrgrmPrd)%>%
                                        select(TarpP3),
                            st_read("Building Data/Program_Predicted_11_21.shp")%>%
                                        mutate(TarpP4 = PrgrmPrd)%>%
                                        select(TarpP4),
                            st_read("Building Data/Program_Predicted_12_4.shp")%>%
                                        mutate(TarpP5 = PrgrmPrd)%>%
                                        select(TarpP5),
                            st_read("Building Data/Program_Predicted_1_10.shp")%>%
                                        mutate(TarpP6 = PrgrmPrd)%>%
                                        select(TarpP6)
                            ) %>%
                              select(-geometry.1,-geometry.2,-geometry.3,-geometry.4,-geometry.5)

Install_Predicted<-Install_Predicted%>%
                        mutate(CovrPrd = 
  ifelse(TarpP1 == "1",  2,
  ifelse(TarpP1 == "0" & TarpP2 =="1",4,
  ifelse(TarpP1 == "0" & TarpP2 =="0" & TarpP3 =="1",6,
  ifelse(TarpP1 == "0" & TarpP2 =="0" & TarpP3 =="0" & TarpP4 =="1",8,                           
  ifelse(TarpP1 == "0" & TarpP2 =="0" & TarpP3 =="0" & TarpP4 =="0" & TarpP5 =="1",10,                            
  NA)))))) # note that we are not concerned with P6 since its out of program range. These have all been confirmed program properties in January.

table(Install_Predicted$CovrPrd)

st_write(Install_Predicted, "Building Data/Install_Predicted.shp")
```




